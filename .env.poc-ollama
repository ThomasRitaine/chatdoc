###################################
####   Multilingual Settings   ####
###################################


# Rephrase the user query in specified languages using LLM, use comma separated values
MULTILINGUAL_QUERY_EXPANSION="English,French"

# A recent MIT license multilingual model: https://huggingface.co/intfloat/multilingual-e5-small
DOCUMENT_ENCODER_MODEL="intfloat/multilingual-e5-base"

# The model above is trained with the following prefix for queries and passages to improve retrieval
# by letting the model know which of the two type is currently being embedded
ASYM_QUERY_PREFIX="query: "
ASYM_PASSAGE_PREFIX="passage: "

# Depends model by model, the one shown above is tuned with this as True
NORMALIZE_EMBEDDINGS="True"

# Use LLM to determine if chunks are relevant to the query
# May not work well for languages that do not have much training data in the LLM training set
# If using a common language like Spanish, French, Chinese, etc. this can be kept turned on
DISABLE_LLM_CHUNK_FILTER="True"

# The default reranking models are English first
# There are no great quality French/English reranking models currently so turning this off
ENABLE_RERANKING_ASYNC_FLOW="False"
ENABLE_RERANKING_REAL_TIME_FLOW="False"

# Enables fine-grained embeddings for better retrieval
# At the cost of indexing speed (~5x slower), query time is same speed
# Since reranking is turned off and multilingual retrieval is generally harder
# it is advised to turn this one on
ENABLE_MINI_CHUNK="True"



##############################
####   General Settings   ####
##############################

# Could be something like danswer.companyname.com
WEB_DOMAIN=http://localhost


# Generative AI settings, uncomment as needed, will work with defaults
GEN_AI_MODEL_PROVIDER=openai
GEN_AI_MODEL_VERSION=gpt-4-turbo-preview
FAST_GEN_AI_MODEL_VERSION=gpt-3.5-turbo-0125
# Provide this as a global default/backup, this can also be set via the UI
#GEN_AI_API_KEY=
# Set to use Azure OpenAI or other services, such as https://danswer.openai.azure.com/
#GEN_AI_API_ENDPOINT=
# Set up to use a specific API version, such as 2023-09-15-preview (example taken from Azure)
#GEN_AI_API_VERSION=

GEN_AI_MODEL_PROVIDER=ollama_chat
# Model of your choice
GEN_AI_MODEL_VERSION=mixtral
# Wherever Ollama is running
# Hint: To point Docker containers to http://localhost:11434, use host.docker.internal instead of localhost
GEN_AI_API_ENDPOINT=http://ollama:11434

# Let's also make some changes to accommodate the weaker locally hosted LLM
QA_TIMEOUT=120  # Set a longer timeout, running models on CPU can be slow
# Always run search, never skip
DISABLE_LLM_CHOOSE_SEARCH=True
# Don't use LLM for reranking, the prompts aren't properly tuned for these models
DISABLE_LLM_CHUNK_FILTER=True
# Don't try to rephrase the user query, the prompts aren't properly tuned for these models
DISABLE_LLM_QUERY_REPHRASE=True
# Don't use LLM to automatically discover time/source filters
DISABLE_LLM_FILTER_EXTRACTION=True
# Uncomment this one if you find that the model is struggling (slow or distracted by too many docs)
# Use only 1 section from the documents and do not require quotes
# QA_PROMPT_OVERRIDE=weak

# The following are for configuring User Authentication, supported flows are:
# disabled
# basic (standard username / password)
# google_oauth (login with google/gmail account)
# oidc (only in Danswer enterprise edition)
# saml (only in Danswer enterprise edition)
AUTH_TYPE=disabled


# How long before user needs to reauthenticate, default to 1 day. (cookie expiration time)
SESSION_EXPIRE_TIME_SECONDS=86400


# Use the below to specify a list of allowed user domains, only checked if user Auth is turned on
# e.g. `VALID_EMAIL_DOMAINS=example.com,example.org` will only allow users
# with an @example.com or an @example.org email
#VALID_EMAIL_DOMAINS=

# Disable telemetry
DISABLE_TELEMETRY=True

# Default values here are what Postgres uses by default, feel free to change.
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password

# Setting more verbose logging
# LOG_LEVEL="debug"
LOG_ALL_MODEL_INTERACTIONS="true"
